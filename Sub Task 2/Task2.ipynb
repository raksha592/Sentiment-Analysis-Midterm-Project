{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as pltfrom\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647 1156\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "with open(\"Headline_Trainingdata.json\") as f:\n",
    "    reviews_train = json.load(f)\n",
    "\n",
    "with open(\"Headline_Trialdata.json\") as f:\n",
    "    reviews_trial = json.load(f)\n",
    "\n",
    "with open(\"Headlines_Testdata.json\", encoding=\"utf8\") as f:\n",
    "    reviews_test = json.load(f)\n",
    "\n",
    "maxlen = 0\n",
    "#pprint(reviews_train)\n",
    "#X_train = [review['title'] for review in reviews_train]\n",
    "#X_trial = [review['title'] for review in reviews_trial]\n",
    "#Y_train = [0 if review['sentiment']<=0 else 1 for review in reviews_train]\n",
    "#Y_trial = [0 if review['sentiment']<=0 else 1 for review in reviews_trial]\n",
    "\n",
    "X_train = []\n",
    "X_test = [review['title'] for review in reviews_test]\n",
    "output = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "for review in reviews_train :\n",
    "    X_train.append(review['title'])\n",
    "    Y_train.append(0 if review['sentiment']<0 else 1)\n",
    "    output.append(review['sentiment'])\n",
    "    if maxlen < len(review['title'].split()) :\n",
    "        maxlen = len(review['title'].split())\n",
    "    \n",
    "for review in reviews_trial :\n",
    "    reviews_train.append(review)\n",
    "    X_train.append(review['title'])\n",
    "    Y_train.append(0 if review['sentiment']<0 else 1)\n",
    "    output.append(review['sentiment'])\n",
    "    if maxlen < len(review['title'].split()) :\n",
    "        maxlen = len(review['title'].split())\n",
    "\n",
    "testMax = 0\n",
    "for review in reviews_test :\n",
    "    if testMax < len(review['title'].split()) :\n",
    "        testMax = len(review['title'].split())\n",
    "print(len(X_train)+len(X_test), len(Y_train))\n",
    "print(testMax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "data = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 16)            240000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 242,129\n",
      "Trainable params: 242,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(15000, 16, input_length=50))\n",
    "model.add(LSTM(16, dropout=0.15, recurrent_dropout=0.15))\n",
    "#model.add(Dense(4, activation='tanh'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 693 samples, validate on 463 samples\n",
      "Epoch 1/75\n",
      "693/693 [==============================] - 2s - loss: 2.2094 - acc: 0.3867 - val_loss: 1.3071 - val_acc: 0.4147\n",
      "Epoch 2/75\n",
      "693/693 [==============================] - 1s - loss: 1.0932 - acc: 0.3867 - val_loss: 0.7971 - val_acc: 0.4147\n",
      "Epoch 3/75\n",
      "693/693 [==============================] - 1s - loss: 0.6984 - acc: 0.5570 - val_loss: 0.6661 - val_acc: 0.5940\n",
      "Epoch 4/75\n",
      "693/693 [==============================] - 1s - loss: 0.6605 - acc: 0.5974 - val_loss: 0.6569 - val_acc: 0.5918\n",
      "Epoch 5/75\n",
      "693/693 [==============================] - 1s - loss: 0.6008 - acc: 0.6854 - val_loss: 0.6439 - val_acc: 0.6544\n",
      "Epoch 6/75\n",
      "693/693 [==============================] - 1s - loss: 0.5402 - acc: 0.7576 - val_loss: 0.6259 - val_acc: 0.6609\n",
      "Epoch 7/75\n",
      "693/693 [==============================] - 1s - loss: 0.4698 - acc: 0.8499 - val_loss: 0.6303 - val_acc: 0.6782\n",
      "Epoch 8/75\n",
      "693/693 [==============================] - 1s - loss: 0.3765 - acc: 0.9019 - val_loss: 0.6022 - val_acc: 0.6933\n",
      "Epoch 9/75\n",
      "693/693 [==============================] - 1s - loss: 0.2709 - acc: 0.9307 - val_loss: 0.5906 - val_acc: 0.6998\n",
      "Epoch 10/75\n",
      "693/693 [==============================] - 1s - loss: 0.1970 - acc: 0.9582 - val_loss: 0.6387 - val_acc: 0.6998\n",
      "Epoch 11/75\n",
      "693/693 [==============================] - 1s - loss: 0.1417 - acc: 0.9755 - val_loss: 0.6728 - val_acc: 0.7019\n",
      "Epoch 12/75\n",
      "693/693 [==============================] - 1s - loss: 0.1001 - acc: 0.9711 - val_loss: 0.7505 - val_acc: 0.7063\n",
      "Epoch 13/75\n",
      "693/693 [==============================] - 1s - loss: 0.0782 - acc: 0.9726 - val_loss: 0.8229 - val_acc: 0.6911\n",
      "Epoch 14/75\n",
      "693/693 [==============================] - 1s - loss: 0.0619 - acc: 0.9668 - val_loss: 0.9264 - val_acc: 0.6933\n",
      "Epoch 15/75\n",
      "693/693 [==============================] - 1s - loss: 0.0496 - acc: 0.9668 - val_loss: 0.9464 - val_acc: 0.7084\n",
      "Epoch 16/75\n",
      "693/693 [==============================] - 1s - loss: 0.0406 - acc: 0.9553 - val_loss: 1.0229 - val_acc: 0.6803\n",
      "Epoch 17/75\n",
      "693/693 [==============================] - 1s - loss: 0.0488 - acc: 0.9639 - val_loss: 1.0665 - val_acc: 0.6933\n",
      "Epoch 18/75\n",
      "693/693 [==============================] - 1s - loss: 0.0384 - acc: 0.9538 - val_loss: 1.0961 - val_acc: 0.6760\n",
      "Epoch 19/75\n",
      "693/693 [==============================] - 1s - loss: 0.0304 - acc: 0.9509 - val_loss: 1.1394 - val_acc: 0.6782\n",
      "Epoch 20/75\n",
      "693/693 [==============================] - 1s - loss: 0.0267 - acc: 0.9380 - val_loss: 1.1798 - val_acc: 0.6717\n",
      "Epoch 21/75\n",
      "693/693 [==============================] - 1s - loss: 0.0280 - acc: 0.9307 - val_loss: 1.1686 - val_acc: 0.6890\n",
      "Epoch 22/75\n",
      "693/693 [==============================] - 1s - loss: 0.0236 - acc: 0.9264 - val_loss: 1.2126 - val_acc: 0.6825\n",
      "Epoch 23/75\n",
      "693/693 [==============================] - 1s - loss: 0.0222 - acc: 0.9336 - val_loss: 1.2482 - val_acc: 0.6847\n",
      "Epoch 24/75\n",
      "693/693 [==============================] - 1s - loss: 0.0323 - acc: 0.9250 - val_loss: 1.2786 - val_acc: 0.6782\n",
      "Epoch 25/75\n",
      "693/693 [==============================] - 1s - loss: 0.0274 - acc: 0.9206 - val_loss: 1.2692 - val_acc: 0.6976\n",
      "Epoch 26/75\n",
      "693/693 [==============================] - 1s - loss: 0.0250 - acc: 0.9235 - val_loss: 1.2663 - val_acc: 0.6911\n",
      "Epoch 27/75\n",
      "693/693 [==============================] - 1s - loss: 0.0218 - acc: 0.9120 - val_loss: 1.2677 - val_acc: 0.6890\n",
      "Epoch 28/75\n",
      "693/693 [==============================] - 1s - loss: 0.0240 - acc: 0.9134 - val_loss: 1.2984 - val_acc: 0.6674\n",
      "Epoch 29/75\n",
      "693/693 [==============================] - 1s - loss: 0.0242 - acc: 0.9365 - val_loss: 1.3129 - val_acc: 0.6890\n",
      "Epoch 30/75\n",
      "693/693 [==============================] - 1s - loss: 0.0262 - acc: 0.9264 - val_loss: 1.3035 - val_acc: 0.6933\n",
      "Epoch 31/75\n",
      "693/693 [==============================] - 1s - loss: 0.0237 - acc: 0.9336 - val_loss: 1.2940 - val_acc: 0.6847\n",
      "Epoch 32/75\n",
      "693/693 [==============================] - 1s - loss: 0.0218 - acc: 0.9149 - val_loss: 1.3442 - val_acc: 0.6803\n",
      "Epoch 33/75\n",
      "693/693 [==============================] - 1s - loss: 0.0197 - acc: 0.9250 - val_loss: 1.3742 - val_acc: 0.6739\n",
      "Epoch 34/75\n",
      "693/693 [==============================] - 1s - loss: 0.0199 - acc: 0.9221 - val_loss: 1.3857 - val_acc: 0.6782\n",
      "Epoch 35/75\n",
      "693/693 [==============================] - 1s - loss: 0.0177 - acc: 0.9278 - val_loss: 1.4377 - val_acc: 0.6674\n",
      "Epoch 36/75\n",
      "693/693 [==============================] - 1s - loss: 0.0198 - acc: 0.9206 - val_loss: 1.4515 - val_acc: 0.6652\n",
      "Epoch 37/75\n",
      "693/693 [==============================] - 1s - loss: 0.0197 - acc: 0.9250 - val_loss: 1.4516 - val_acc: 0.6674\n",
      "Epoch 38/75\n",
      "693/693 [==============================] - 1s - loss: 0.0211 - acc: 0.8903 - val_loss: 1.4550 - val_acc: 0.6695\n",
      "Epoch 39/75\n",
      "693/693 [==============================] - 1s - loss: 0.0188 - acc: 0.9120 - val_loss: 1.4801 - val_acc: 0.6674\n",
      "Epoch 40/75\n",
      "693/693 [==============================] - 1s - loss: 0.0216 - acc: 0.9120 - val_loss: 1.4887 - val_acc: 0.6631\n",
      "Epoch 41/75\n",
      "693/693 [==============================] - 1s - loss: 0.0203 - acc: 0.9091 - val_loss: 1.4887 - val_acc: 0.6760\n",
      "Epoch 42/75\n",
      "693/693 [==============================] - 1s - loss: 0.0203 - acc: 0.9048 - val_loss: 1.4846 - val_acc: 0.6803\n",
      "Epoch 43/75\n",
      "693/693 [==============================] - 1s - loss: 0.0200 - acc: 0.9004 - val_loss: 1.5040 - val_acc: 0.6739\n",
      "Epoch 44/75\n",
      "693/693 [==============================] - 1s - loss: 0.0197 - acc: 0.9062 - val_loss: 1.5019 - val_acc: 0.6674\n",
      "Epoch 45/75\n",
      "693/693 [==============================] - 1s - loss: 0.0185 - acc: 0.9062 - val_loss: 1.5077 - val_acc: 0.6695\n",
      "Epoch 46/75\n",
      "693/693 [==============================] - 1s - loss: 0.0185 - acc: 0.9105 - val_loss: 1.4851 - val_acc: 0.6652\n",
      "Epoch 47/75\n",
      "693/693 [==============================] - 1s - loss: 0.0219 - acc: 0.8932 - val_loss: 1.4920 - val_acc: 0.6739\n",
      "Epoch 48/75\n",
      "693/693 [==============================] - 1s - loss: 0.0191 - acc: 0.9033 - val_loss: 1.5078 - val_acc: 0.6695\n",
      "Epoch 49/75\n",
      "693/693 [==============================] - 1s - loss: 0.0179 - acc: 0.8990 - val_loss: 1.5284 - val_acc: 0.6760\n",
      "Epoch 50/75\n",
      "693/693 [==============================] - 1s - loss: 0.0179 - acc: 0.8975 - val_loss: 1.5458 - val_acc: 0.6717\n",
      "Epoch 51/75\n",
      "693/693 [==============================] - 1s - loss: 0.0209 - acc: 0.8961 - val_loss: 1.5547 - val_acc: 0.6695\n",
      "Epoch 52/75\n",
      "693/693 [==============================] - 1s - loss: 0.0203 - acc: 0.8975 - val_loss: 1.5462 - val_acc: 0.6760\n",
      "Epoch 53/75\n",
      "693/693 [==============================] - 1s - loss: 0.0188 - acc: 0.8961 - val_loss: 1.5645 - val_acc: 0.6739\n",
      "Epoch 54/75\n",
      "693/693 [==============================] - 1s - loss: 0.0189 - acc: 0.8918 - val_loss: 1.5719 - val_acc: 0.6760\n",
      "Epoch 55/75\n",
      "693/693 [==============================] - 1s - loss: 0.0181 - acc: 0.9033 - val_loss: 1.5650 - val_acc: 0.6652\n",
      "Epoch 56/75\n",
      "693/693 [==============================] - 1s - loss: 0.0190 - acc: 0.8947 - val_loss: 1.5709 - val_acc: 0.6674\n",
      "Epoch 57/75\n",
      "693/693 [==============================] - 1s - loss: 0.0178 - acc: 0.9076 - val_loss: 1.6030 - val_acc: 0.6652\n",
      "Epoch 58/75\n",
      "693/693 [==============================] - 1s - loss: 0.0190 - acc: 0.9105 - val_loss: 1.5950 - val_acc: 0.6695\n",
      "Epoch 59/75\n",
      "693/693 [==============================] - 1s - loss: 0.0209 - acc: 0.9062 - val_loss: 1.5707 - val_acc: 0.6782\n",
      "Epoch 60/75\n",
      "693/693 [==============================] - 1s - loss: 0.0188 - acc: 0.9033 - val_loss: 1.5705 - val_acc: 0.6868\n",
      "Epoch 61/75\n",
      "693/693 [==============================] - 1s - loss: 0.0167 - acc: 0.8961 - val_loss: 1.5645 - val_acc: 0.6825\n",
      "Epoch 62/75\n",
      "693/693 [==============================] - 1s - loss: 0.0203 - acc: 0.8975 - val_loss: 1.5588 - val_acc: 0.6803\n",
      "Epoch 63/75\n",
      "693/693 [==============================] - 1s - loss: 0.0186 - acc: 0.8889 - val_loss: 1.5657 - val_acc: 0.6760\n",
      "Epoch 64/75\n",
      "693/693 [==============================] - 1s - loss: 0.0187 - acc: 0.9004 - val_loss: 1.6083 - val_acc: 0.6760\n",
      "Epoch 65/75\n",
      "693/693 [==============================] - 1s - loss: 0.0181 - acc: 0.9062 - val_loss: 1.5132 - val_acc: 0.6760\n",
      "Epoch 66/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693/693 [==============================] - 1s - loss: 0.0195 - acc: 0.8874 - val_loss: 1.5738 - val_acc: 0.6782\n",
      "Epoch 67/75\n",
      "693/693 [==============================] - 1s - loss: 0.0178 - acc: 0.9048 - val_loss: 1.5924 - val_acc: 0.6695\n",
      "Epoch 68/75\n",
      "693/693 [==============================] - 1s - loss: 0.0189 - acc: 0.8990 - val_loss: 1.5825 - val_acc: 0.6933\n",
      "Epoch 69/75\n",
      "693/693 [==============================] - 1s - loss: 0.0200 - acc: 0.8932 - val_loss: 1.5923 - val_acc: 0.6868\n",
      "Epoch 70/75\n",
      "693/693 [==============================] - 1s - loss: 0.0197 - acc: 0.8860 - val_loss: 1.5769 - val_acc: 0.6717\n",
      "Epoch 71/75\n",
      "693/693 [==============================] - 1s - loss: 0.0219 - acc: 0.8918 - val_loss: 1.6166 - val_acc: 0.6847\n",
      "Epoch 72/75\n",
      "693/693 [==============================] - 1s - loss: 0.0180 - acc: 0.8961 - val_loss: 1.5722 - val_acc: 0.6890\n",
      "Epoch 73/75\n",
      "693/693 [==============================] - 1s - loss: 0.0194 - acc: 0.8846 - val_loss: 1.6088 - val_acc: 0.6868\n",
      "Epoch 74/75\n",
      "693/693 [==============================] - 1s - loss: 0.0175 - acc: 0.8961 - val_loss: 1.6254 - val_acc: 0.6890\n",
      "Epoch 75/75\n",
      "693/693 [==============================] - 1s - loss: 0.0176 - acc: 0.9048 - val_loss: 1.6212 - val_acc: 0.6782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = model.fit(data, np.array(Y_train), validation_split=0.4, epochs=75,verbose = 1)\n",
    "\n",
    "#plot_training_curves(history.history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5390725]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Anuja\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(np.array(X_train))\n",
    "data = pad_sequences(sequences, maxlen=50)\n",
    "predictions = model.predict(data)\n",
    "predictedVals = [pr[0] for pr in predictions ]\n",
    "\n",
    "similarity = cosine_similarity(output,predictedVals) \n",
    "\n",
    "\n",
    "print(similarity)\n",
    "\n",
    "#print(\"\\t\\t\\tHEADLINE\\t\\t\\t\\t| GS | PS |\")\n",
    "#for i in range(len(predictions)):\n",
    "#    print(X_train[i],\"|\",output[i],\"|\",\"%.3f\" % predictions[i],\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>Predicted Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morrisons</td>\n",
       "      <td>2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>Morrisons book second consecutive quarter of s...</td>\n",
       "      <td>0.999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMI</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>IMI posts drop in first-quarter organic revenu...</td>\n",
       "      <td>-0.290707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glencore</td>\n",
       "      <td>4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>Glencore to refinance its short-term debt earl...</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryanair</td>\n",
       "      <td>5</td>\n",
       "      <td>0.259</td>\n",
       "      <td>EasyJet attracts more passengers in June but s...</td>\n",
       "      <td>0.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barclays</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>Barclays 'bad bank' chief to step down</td>\n",
       "      <td>-0.490590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  id  sentiment  \\\n",
       "0  Morrisons   2      0.430   \n",
       "1        IMI   3     -0.344   \n",
       "2   Glencore   4      0.340   \n",
       "3    Ryanair   5      0.259   \n",
       "4   Barclays   6     -0.231   \n",
       "\n",
       "                                               title  \\\n",
       "0  Morrisons book second consecutive quarter of s...   \n",
       "1  IMI posts drop in first-quarter organic revenu...   \n",
       "2  Glencore to refinance its short-term debt earl...   \n",
       "3  EasyJet attracts more passengers in June but s...   \n",
       "4             Barclays 'bad bank' chief to step down   \n",
       "\n",
       "   Predicted Sentiment Score  \n",
       "0                   0.999733  \n",
       "1                  -0.290707  \n",
       "2                   0.999891  \n",
       "3                   0.999877  \n",
       "4                  -0.490590  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(reviews_train)\n",
    "df['Predicted Sentiment Score'] = predictedVals\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('Task2_train.csv', sep = \",\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
